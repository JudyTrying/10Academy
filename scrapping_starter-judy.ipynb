{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scrapping using python\n",
    "\n",
    "#### References\n",
    "1. [Practical Introduction to Web Scraping in Python](https://realpython.com/python-web-scraping-practical-introduction/)\n",
    "2. [Web Scraping using Python](https://www.datacamp.com/community/tutorials/web-scraping-using-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ python3 -m venv venv\n",
    "# $ . ./venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "import fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile ../pyscrap_url.py\n",
    "\n",
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content  #.encode(BeautifulSoup.original_encoding)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns True if the response seems to be HTML, False otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "\n",
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    It is always a good idea to log errors. \n",
    "    This function just prints them, but you can\n",
    "    make it do anything.\n",
    "    \"\"\"\n",
    "    print(e)\n",
    "    \n",
    "def get_elements(url, tag='',search={}, fname=None):\n",
    "    \"\"\"\n",
    "    Downloads a page specified by the url parameter\n",
    "    and returns a list of strings, one per tag element\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(url,str):\n",
    "        response = simple_get(url)\n",
    "    else:\n",
    "        #if already it is a loaded html page\n",
    "        response = url\n",
    "\n",
    "    if response is not None:\n",
    "        html = BeautifulSoup(response, 'html.parser')\n",
    "        \n",
    "        res = []\n",
    "        if tag:    \n",
    "            for li in html.select(tag):\n",
    "                for name in li.text.split('\\n'):\n",
    "                    if len(name) > 0:\n",
    "                        res.append(name.strip())\n",
    "                       \n",
    "                \n",
    "        if search:\n",
    "            soup = html            \n",
    "            \n",
    "            \n",
    "            r = ''\n",
    "            if 'find' in search.keys():\n",
    "                print('findaing',search['find'])\n",
    "                soup = soup.find(**search['find'])\n",
    "                r = soup\n",
    "\n",
    "                \n",
    "            if 'find_all' in search.keys():\n",
    "                print('findaing all of',search['find_all'])\n",
    "                r = soup.find_all(**search['find_all'])\n",
    "   \n",
    "            if r:\n",
    "                for x in list(r):\n",
    "                    if len(x) > 0:\n",
    "                        res.extend(x)\n",
    "            \n",
    "        return res\n",
    "\n",
    "    # Raise an exception if we failed to get any data from the url\n",
    "    raise Exception('Error retrieving contents at {}'.format(url))    \n",
    "    \n",
    "    \n",
    "if get_ipython().__class__.__name__ == '__main__':\n",
    "    fire(get_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100. Jeffrey Gettleman (@gettleman)',\n",
       " '99. Africa24 Media (@a24media)',\n",
       " '98. Scapegoat (@andiMakinana)',\n",
       " '97. Africa Check (@AfricaCheck)',\n",
       " '96. James Copnall (@JamesCopnall)',\n",
       " '95. Online Africa (@oafrica)',\n",
       " '94. Patrick Ngowi (@PatrickNgowi)',\n",
       " '93. DOS African Affairs (@StateAfrica)',\n",
       " '92. MoadowAJE (@Moadow)',\n",
       " '91. Brendan Boyle (@BrendanSAfrica)',\n",
       " '90. City of Tshwane (@CityTshwane)',\n",
       " '89. VISI Magazine (@VISI_Mag)',\n",
       " '88. andBeyond (@andBeyondSafari)',\n",
       " '87. This Is Africa (@ThisIsAfricaTIA)',\n",
       " '86. Sarah Carter (@sarzss)',\n",
       " '85. The EIU Africa team (@TheEIU_Africa)',\n",
       " '84. Investing In Africa (@InvestInAfrica)',\n",
       " '83. Barry Malone (@malonebarry)',\n",
       " '82. ARTsouthAFRICA (@artsouthafrica)',\n",
       " '81. Kahn Morbee (@KahnMorbee)',\n",
       " '80. Jamal Osman (@JamalMOsman)',\n",
       " '79. iamsuedeâ„¢ (@iamsuede)',\n",
       " '78. Mike Stopforth (@mikestopforth)',\n",
       " '77. Equal Education (@equal_education)',\n",
       " '76. Tristan McConnell (@t_mcconnell)',\n",
       " '75. Kate Forbes (@forbeesta)',\n",
       " '74. Vanessa Raphaely (@hurricanevaness)',\n",
       " '73. Karen Allen (@BBCKarenAllen)',\n",
       " '72. Jax Panik (@jaxpanik)',\n",
       " '71. This Is Africa (@thisisafrica)',\n",
       " '70. Audi South Africa (@audisouthafrica)',\n",
       " '69. ONE (@ONEinAfrica)',\n",
       " '68. Hamza Mohamed (@Hamza_Africa)',\n",
       " '67. drew hinshaw (@drewfhinshaw)',\n",
       " '66. Rebecca Enonchong (@africatechie)',\n",
       " '65. marais (@cx73)',\n",
       " '64. George Ayittey (@ayittey)',\n",
       " '63. Mercedes-Benz SA (@MercedesBenz_SA)',\n",
       " '62. Africa Gathering (@africagathering)',\n",
       " '61. okayafrica (@okayafrica)',\n",
       " '60. Mary Harper (@mary_harper)',\n",
       " '59. Save the Rhino (@savetherhino)',\n",
       " '58. africa @pressfreedom (@africamedia_CPJ)',\n",
       " '57. TechCentral (@TechCentral)',\n",
       " '56. GautengGovt (@GautengProvince)',\n",
       " '55. Abdi Aynte (@Aynte)',\n",
       " '54. Daniel Howden (@daniel_howden)',\n",
       " '53. Ranger Diaries (@rangerdiaries)',\n",
       " '52. The Star (@TheStar_news)',\n",
       " '51. James Schneider (@schneiderhome)',\n",
       " '50. Afrinnovator (@Afrinnovator)',\n",
       " '49. theafricareport (@theafricareport)',\n",
       " '48. City of Joburg (@CityofJoburgZA)',\n",
       " '47. Think Africa Press (@ThinkAfricaFeed)',\n",
       " '46. Africa The Good News (@AfricaGoodNews)',\n",
       " '45. will ross (@willintune)',\n",
       " '44. CNBC Africa (@cnbcafrica)',\n",
       " '43. HowWeMadeItInAfrica (@MadeItInAfrica)',\n",
       " '42. Africa Research Inst (@AfricaResearch)',\n",
       " '41. FoodBlog Cape Town (@FoodBlogCT)',\n",
       " '40. Mbuyiseni Ndlozi (@MbuyiseniNdlozi)',\n",
       " '39. AfricaProgressPanel (@africaprogress)',\n",
       " '38. IFC Africa (@IFCAfrica)',\n",
       " '37. Henley Africa (@HenleyAfrica)',\n",
       " '36. The New Age (@The_New_Age)',\n",
       " '35. Geoffrey York (@geoffreyyork)',\n",
       " '34. Entrepreneur Mag SA (@Entrepreneur_SA)',\n",
       " '33. Forbes Africa (@forbesafrica)',\n",
       " '32. IEC South Africa (@IECSouthAfrica)',\n",
       " '31. Arthur Goldstuck (@art2gee)',\n",
       " '30. Jendayi E Frazer (@JendayiFrazer)',\n",
       " '29. Peter Greste (@PeterGreste)',\n",
       " '28. Disaster Operations (@NDOCKenya)',\n",
       " '27. Mo Ibrahim Fdn (@Mo_IbrahimFdn)',\n",
       " '26. Parliament of RSA (@ParliamentofRSA)',\n",
       " '25. Sandton City (@SandtonCity)',\n",
       " '24. African Union (@_AfricanUnion)',\n",
       " '23. Gert-Johan Coetzee (@gertjohan)',\n",
       " '22. David Smith (@SmithInAfrica)',\n",
       " '21. Ray Hartley (@hartleyr)',\n",
       " '20. Live Amp (@liveamp)',\n",
       " '19. Samsung South Africa (@SamsungSA)',\n",
       " '18. Bob Skinstad (@BobSkinstad)',\n",
       " '17. Camfed (@Camfed)',\n",
       " '16. andrew harding (@BBCAndrewH)',\n",
       " '15. Euphonikâ„¢â™› (@euphonik)',\n",
       " '14. Ulrich J van Vuuren (@UlrichJvV)',\n",
       " '13. John Robbie (@702JohnRobbie)',\n",
       " '12. Cricket South Africa (@OfficialCSA)',\n",
       " '11. MTV Base Africa (@MTVbaseAfrica)',\n",
       " '10. Computicket (@Computicket)',\n",
       " '9. loyiso gola (@loyisogola)',\n",
       " '8. 5FM (@5FM)',\n",
       " '7. mailandguardian (@mailandguardian)',\n",
       " '6. Helen Zille (@helenzille)',\n",
       " '5. Julius Sello Malema (@Julius_S_Malema)',\n",
       " '4. News24 (@News24)',\n",
       " '3. Jacob G. Zuma (@SAPresident)',\n",
       " '2. Gareth Cliff (@GarethCliff)',\n",
       " '1. Trevor Noah (@Trevornoah)']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = get_elements('https://africafreak.com/100-most-influential-twitter-users-in-africa', tag='h2')\n",
    "influencers = res[:-5]\n",
    "influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store res in a csv file\n",
    "df_influencers = pd.DataFrame(influencers)\n",
    "df_influencers.to_csv('influencer.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5. Julius Sello Malema (@Julius_S_Malema)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4. News24 (@News24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3. Jacob G. Zuma (@SAPresident)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2. Gareth Cliff (@GarethCliff)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1. Trevor Noah (@Trevornoah)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0\n",
       "95  5. Julius Sello Malema (@Julius_S_Malema)\n",
       "96                        4. News24 (@News24)\n",
       "97            3. Jacob G. Zuma (@SAPresident)\n",
       "98             2. Gareth Cliff (@GarethCliff)\n",
       "99               1. Trevor Noah (@Trevornoah)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_influencers.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "handles = []\n",
    "\n",
    "for i in influencers:\n",
    "    first_split = i.split(\"(\")\n",
    "    second_split = first_split[0].split(\".\")\n",
    "    name.append(second_split[1])\n",
    "    handles.append(first_split[1])\n",
    "    #store in a dictonary\n",
    "    influencers_dict = {\"Name\":name, \"handles\":handles}\n",
    "    #convert to data frame\n",
    "    df_influencers_new = pd.DataFrame(influencers_dict)\n",
    "    \n",
    "df_influencers_new.to_csv(\"influencers_new.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://www.atlanticcouncil.org/blogs/africasource/african-leaders-respond-to-coronavirus-on-twitter/#east-africa'\n",
    "response = simple_get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "findaing all of {'class_': 'css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#res = get_elements(response, search={'find_all':{'class_':'css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0'}})\n",
    "#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from selenium) (1.25.8)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\spectre\\anaconda3\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: BeautifulSoup4 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (4.8.2)\n",
      "Requirement already satisfied: fire in c:\\users\\spectre\\anaconda3\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from BeautifulSoup4) (1.9.5)\n",
      "Requirement already satisfied: termcolor in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from fire) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from fire) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests BeautifulSoup4 fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying another way\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "findaing all of {'class_': 'wp-block-embed__wrapper'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The Deputy Prime Minister Themba Masuku has today met representatives of the private sector and employees' unions to map a collaborative effort in the fight against #COVID19. pic.twitter.com/EIYNGOEKRNâ€” Eswatini Government (@EswatiniGovern1) March 20, 2020\",\n",
       " 'GUIDELINES FOR SCHOOLS IN #MALAWI ON THE PREVENTION AND MANAGEMENT OF #COVID19 #CORONAVIRUS pic.twitter.com/PL9R4XvGV3â€” Malawi Government (@MalawiGovt) March 18, 2020',\n",
       " 'Fellow Namibians, I declared a State of Emergency on #COVID19. Cabinet approved additonal measures and responses to contain the spread of the Coronavirus. pic.twitter.com/OsjrguArxfâ€” Hage G. Geingob (@hagegeingob) March 18, 2020',\n",
       " '#COVID19measuresSC #PrivateSector \"Government will guarantee the salaries of all employees in the private sector for the months of April, May and June. A total of SCR1.2 billion has been budgeted for this intervention. Government will not approve any redundancies.\"â€” Seychelles Ministry of Finance (@FinanceSC) March 20, 2020',\n",
       " 'The Minister for Cooperative Governance & Traditional Affairs (COGTA) has, in terms of section 3 of the Disaster Management Act, 2002 (Act No. 57 of 2002), made the and gazetted regulations to deal with the spread of Regulations in the Schedule. #COVID19 #CoronaVirusSA pic.twitter.com/3iPRnVebcsâ€” PresidencyZA (@PresidencyZA) March 19, 2020',\n",
       " 'Join the #SafeHands\\xa0 Challenge. The key is preventing the spread of #COVID19 @Dora_Siliya @ChitaluChilufy3 @noalaskinner @coumbagadio_ZM @unicefzambia @UNZambia pic.twitter.com/vLoc72v5Npâ€” Ministry of Health Zambia (@mohzambia) March 18, 2020',\n",
       " 'I urge my fellow Zimbabweans to maintain excellent levels of personal hygiene. Wash your hands thoroughly with soap, cover your nose & mouth with a tissue when you cough, & avoid unnecessary travel abroad.  We must keep our nation, safe, secure & healthy.â€” President of Zimbabwe (@edmnangagwa) March 12, 2020',\n",
       " '#COVID19DJ : FERMETURE DES MOSQUÃ‰ESVoici CommuniquÃ© du MinistÃ¨re des affaires musulmanes et des biens Warkfs. pic.twitter.com/AQ2kQP254jâ€” MinSantÃ©dj (@MinSantedj) March 20, 2020',\n",
       " 'The Ministry of Health announced this evening the first confirmed case of a Coronavirus patient who arrived at Asmara International Airport from Norway with Fly Dubai at 7:00 a.m. LT this morning.  The 39-year old patient is an Eritrean national with permanent residence in Norwayâ€” Yemane G. Meskel (@hawelti) March 21, 2020',\n",
       " 'Please join His Excellency President Uhuru Kenyatta this Saturday, 21st March 2020 at 12 noon for a broadcast prayer service to mark the National Day of Prayer on the Coronavirus pandemic. The Service will be led by a cross-section of religious leaders. pic.twitter.com/kDZPDUpeGzâ€” State House Kenya (@StateHouseKenya) March 20, 2020',\n",
       " 'I joined @WHO #SafeHands challenge. Handwashing is key to preventing the spread of #COVID19. I challenge President Kenyatta @StateHouseKenya, @Macky_Sall, @MagufuliJP, President Tshisekedi @Presidence_RDC,  @CyrilRamaphosa, @BorisJohnson, @KGeorgieva to join in by sharing a video pic.twitter.com/udaVPCexCJâ€” Paul Kagame (@PaulKagame) March 15, 2020',\n",
       " 'We commend all medical practitioners across the globe working hard to counter the #CoronavirusPandemic. I urge everyone to support all efforts and recommended medical measures to slow the spread of #COVID19 and keep the numbers low. pic.twitter.com/AFtDg7Vtooâ€” Mohamed Farmaajo (@M_Farmaajo) March 16, 2020',\n",
       " '20 March 2020: Communication from the #SouthSudan Presidency on the Coronavirus (COVID-19) Pandemic  \"South Sudan remains #COVID19-free. It is time to protect our people.\" â€” H.E Hussein Abdelbagi Akol, VP pic.twitter.com/dZigOXyW2Vâ€” South Sudan Government (@SouthSudanGov) March 20, 2020',\n",
       " 'There is no shame in not shaking hands and in social distancing, during these difficult times, we must protect ourselves and those around us.Prevention is the best cure, therefore please be sure to follow health safety and security instructions.#Ø§Ø­ØªÙŠØ§Ø·Ø§Øª_Ø§Ù„Ø³ÙˆØ¯Ø§Ù†_Ù„Ù…Ù†Ø¹_ÙƒÙˆØ±ÙˆÙ†Ø§ pic.twitter.com/abrg7Pvb5wâ€” Abdalla Hamdok (@SudanPMHamdok) March 19, 2020',\n",
       " 'We have confirmed first case of Corona patient in Tanzania. The government was prepared with isolation centers and isolation hospitals. More measures to curb the spread will continue to be announced. In the meantime, let us continue to observe health precautions.Dr. H.Aâ€” TanzaniaSpokesperson (@TZSpokesperson) March 16, 2020',\n",
       " 'We believe that we can never do enough in the face of corona virus unless God is with us.We shall hold prayers as a nation at State House, Entebbe. Join us from wherever you will be pic.twitter.com/voLCrF8nPKâ€” Yoweri K Museveni (@KagutaMuseveni) March 20, 2020',\n",
       " 'Minister Manuel Augusto participating at SADC Council of Ministers Meeting  from the Ministry in Luanda through videoconference, due to the Coronavirus outbreak. The meeting was conducted from Dar Es Salaam,Tanzania from 16 to 18/3. Tanzania holds the current presidency of SADC. pic.twitter.com/vOfLwRizKrâ€” MOFA/MRE -(Angola) (@angola_Mirex) March 19, 2020',\n",
       " 'ðŸ”´ Une rumeur de mauvais goÃ»t sur le #coronavirus est propagÃ©e par un ancien milicien sans-Ã©chec tout en identifiant, dans sa publication, dâ€™honnÃªtes personnes, dans le but de saboter lâ€™investissement au #Burundi et semer la panique comme ils ont lâ€™habitude de le faire.#COVID19 pic.twitter.com/x4VrMaXF16â€” Amb. Willy Nyamitwe (@willynyamitwe) March 15, 2020',\n",
       " \"La situation du premier patient testÃ© positif au COVID-19 et pris en charge depuis hier par les services mÃ©dicaux compÃ©tents, s'amÃ©liore, et l'Ambassade de son pays suit l'Ã©volution de l'Ã©tat de sa santÃ©.â€” ChÃ©rif Mahamat Zene (@Cherif_MZ) March 20, 2020\",\n",
       " '#RDC 19.03.20| #Stop #Covid_19 #COVID19RDC #coronavirus #PresidenceCD pic.twitter.com/q2dpBcX7C6â€” PrÃ©sidence RDC ðŸ‡¨ðŸ‡© (@Presidence_RDC) March 19, 2020',\n",
       " \"Pour ralentir la diffusion du Covid-19 au Gabon et ainsi en attÃ©nuer au maximum l'impact sur le plan sanitaire, j'ai dÃ©cidÃ© lors du conseil des ministres ce lundi de renforcer les mesures prÃ©ventives. pic.twitter.com/LzkrkwyorBâ€” Ali Bongo Ondimba (@PresidentABO) March 16, 2020\",\n",
       " \"Pour rÃ©duire les risques de propagation du #Coronavirus, le @gouvbenin vous invite Ã  adopter ces gestes barriÃ¨res au #COVID19 . Se protÃ©ger et protÃ©ger les autres, c'est le devoir du citoyen responsable.Toutes les infos utiles sur : https://t.co/eimzSLmTVF pic.twitter.com/OanWPLnnDBâ€” PrÃ©sidence du BÃ©nin (@PresidenceBenin) March 19, 2020\",\n",
       " \"J'invite mes compatriotes Ã  adopter des mesures prÃ©ventives, afin de se prÃ©munir contre le Coronavirus et Ã©viter sa propagation. Ensemble, adoptons des comportements individuels et collectifs adÃ©quats, en suivant les conseils des services de santÃ©.#BurkinaFaso #COVID19 pic.twitter.com/aM8y0srZqJâ€” Roch KABORE (@rochkaborepf) March 11, 2020\",\n",
       " '#prevenÃ§Ã£ocovid19 https://t.co/hiI3LwtWjvâ€” Presidente Cabo Verde (@PresidenciaCV) March 20, 2020',\n",
       " 'Mes chers compatriotes, face Ã  la pandÃ©mie du Coronavirus COVID-19, adoptons les bonnes pratiques et mettons en application les mesures de prÃ©vention recommandÃ©es par le MinistÃ¨re de la SantÃ© et lâ€™OMS. https://t.co/cSxzODR6Vs pic.twitter.com/tILcYxVCf8â€” Alassane Ouattara (@AOuattara_PRCI) March 16, 2020',\n",
       " '#COVID19 awareness campaign: H.E the Vice President Dr Isatou Touray. pic.twitter.com/FhADcBZVsLâ€” State House of The Gambia (@Presidency_GMB) March 19, 2020',\n",
       " 'Here are excerpts of my address to the nation on the updates taken to combat the spread of Coronavirus pic.twitter.com/dkfcrrEiy5â€” Nana Akufo-Addo (@NAkufoAddo) March 15, 2020',\n",
       " 'Dans un contexte de crise #sanitaire mondiale, jâ€™ai pris de nouvelles mesures afin dâ€™endiguer la propagation du #Covid19 en RÃ©publique de #GuinÃ©e#Kibaro #Covid19GN #CoronaVirusUpdate pic.twitter.com/3GAibFbONnâ€” Pr. Alpha CONDÃ‰ (@President_GN) March 19, 2020',\n",
       " \"#GuineaBissau 's borders closed.â€” Umaro Sissoco Embalo (@USEmbalo) March 17, 2020\",\n",
       " 'CommuniquÃ© intÃ©grale du Conseil Extraordinaire de DÃ©fense prÃ©sidÃ© ce 17 Mars par le Chef de lâ€™Etat sur le #coronavirus pic.twitter.com/i3AOlM8Jk7â€” Presidence Mali (@PresidenceMali) March 17, 2020',\n",
       " 'Chers citoyens et rÃ©sidents, Un cas de Covid-19 concernant un citoyen Ã©tranger ayant Ã©tÃ© confirmÃ©, je voudrais vous rassurer que les dispositions ont Ã©tÃ© prises Ã  tous les niveaux. Je vous engage Ã  la prudence et au strict respect  des directives des autoritÃ©s  compÃ©tentes.â€” Mohamed Cheikh El Ghazouani Ù…Ø­Ù…Ø¯ Ø§Ù„Ø´ÙŠØ® Ø§Ù„ØºØ²ÙˆØ§Ù†ÙŠ (@CheikhGhazouani) March 14, 2020',\n",
       " 'Mes Chers Concitoyens, Depuis la grippe Espagnole, il y a un siÃ¨cle, lâ€™ humanitÃ© nâ€™a pas connu un flÃ©au sanitaire dâ€™ une telle ampleur. Je le rÃ©pÃ¨te: il nâ€™y a ni traitement, ni vaccin. Notre seule arme reste la prÃ©vention. https://t.co/akIhqXETrWâ€” Issoufou Mahamadou (@IssoufouMhm) March 17, 2020',\n",
       " 'Protecting Nigerians from the Coronavirus is a key priority for us as a Government. We have the Ministry of Health and the Nigeria Center for Disease Control (NCDC) working round-the-clock with several other agencies, as well as State Governments, to ensure this.â€” Muhammadu Buhari (@MBuhari) March 20, 2020',\n",
       " 'Dear President @PaulKagame, I accept the challenge and encourage all people from Senegal and all contaminated countries to do as well against #COVID19 #SafeHandsWhat about you? pic.twitter.com/1ga1ZCwYfbâ€” Macky Sall (@Macky_Sall) March 17, 2020',\n",
       " 'Although there are no confirmed #Coronavirus cases in #SierraLeone at this time, the Ministry of Health and Sanitation has activated the Emergency Operations Centre to Level 2 to coordinate initial preparedness and response. We have activated the Emergency contact number 117.â€” President Julius Maada Bio (@PresidentBio) March 18, 2020',\n",
       " \"Manifestations coronavirus pic.twitter.com/mdjyRWUuoqâ€” MinistÃ¨re de la SantÃ© et de l'hygiÃ¨ne Publique (@MSPS_Togo) March 17, 2020\"]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# african_leaders = []\n",
    "# soup = BeautifulSoup(url)\n",
    "# for a in soup.findAll('a', href=True, tag= 'blockquote'):\n",
    "#     african_leaders = a.find('span', tag='blockquote')\n",
    "# african_leaders\n",
    "\n",
    "# #will come back to this later. Lemme continue with top 100 influencers\n",
    "res = get_elements(response, search={'find_all':{'class_':'wp-block-embed__wrapper'}})\n",
    "gov = get_elements(url, tag='blockquote')\n",
    "gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the data again\n",
    "#will come back to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting tweets using handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "# to view all columns\n",
    "pd.set_option(\"display.max.columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-3.9.0-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from tweepy) (2.22.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from tweepy) (1.14.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (1.25.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
      "Installing collected packages: tweepy\n",
      "Successfully installed tweepy-3.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.14.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\spectre\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\spectre\\anaconda3\\lib\\site-packages (from nltk) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SPECTRE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweet-preprocessor\n",
      "  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: tweet-preprocessor\n",
      "Successfully installed tweet-preprocessor-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "  '''\n",
    "  This is to print nicely DataFrame wide tables\n",
    "  '''\n",
    "  pd.set_option('display.max_rows', len(x))\n",
    "  pd.set_option('display.max_columns', None)\n",
    "  pd.set_option('display.width', 2000)\n",
    "  pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
    "  pd.set_option('display.max_colwidth', -1)\n",
    "  print(x)\n",
    "  pd.reset_option('display.max_rows')\n",
    "  pd.reset_option('display.max_columns')\n",
    "  pd.reset_option('display.width')\n",
    "  pd.reset_option('display.float_format')\n",
    "  pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tweetsearch():\n",
    "    '''\n",
    "    This is a basic class to search and download twitter data.\n",
    "    You can build up on it to extend the functionalities for more \n",
    "    sophisticated analysis\n",
    "    '''\n",
    "    def __init__(self, cols=None,auth=None):\n",
    "        #\n",
    "        if not cols is None:\n",
    "            self.cols = cols\n",
    "        else:\n",
    "            self.cols = ['id', 'created_at', 'source', 'original_text','clean_text', \n",
    "                    'sentiment','polarity','subjectivity', 'lang',\n",
    "                    'favorite_count', 'retweet_count', 'original_author',   \n",
    "                    'possibly_sensitive', 'hashtags',\n",
    "                    'user_mentions', 'place', 'place_coord_boundaries']\n",
    "            \n",
    "        if auth is None:\n",
    "            consumer_key = 'ujTOvqIRavCVICVUBi4vw2q53'\n",
    "            consumer_secret = 'yjzJxrj1S9aNsmdLhjU0flz8lNgjYDsoG4LXGXwDajxySAe4Rr'\n",
    "            access_key= '3403180215-eeVyPBT3lcPW3uB5womtBvYVP2kXRxPImg3dcjk'\n",
    "            access_secret = 'olbu14CQniYwzldREuFPLzKxjRXi1VadP0IkzOzlA4AmW'\n",
    "            \n",
    "            #Variables that contains the user credentials to access Twitter API \n",
    "#             consumer_key = os.environ.get('TWITTER_API_KEY')\n",
    "#             consumer_secret = os.environ.get('TWITTER_API_SECRET')\n",
    "#             access_token = os.environ.get('TWITTER_ACCESS_TOKEN')\n",
    "#             access_token_secret = os.environ.get('TWITTER_ACCESS_TOKEN_SECRET')\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            #This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "            auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            auth.set_access_token(access_token, access_token_secret)\n",
    "            \n",
    "\n",
    "        #            \n",
    "        self.auth = auth\n",
    "        self.api = tweepy.API(auth,wait_on_rate_limit=True) \n",
    "        self.filtered_tweet = ''\n",
    "           \n",
    "            #authorization successful\n",
    "\n",
    "    def clean_tweets(self, twitter_text):\n",
    "\n",
    "        #use pre processor\n",
    "        tweet = p.clean(twitter_text)\n",
    "\n",
    "         #HappyEmoticons\n",
    "        emoticons_happy = set([\n",
    "            ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "            ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "            '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "            'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "            '<3'\n",
    "            ])\n",
    "\n",
    "        # Sad Emoticons\n",
    "        emoticons_sad = set([\n",
    "            ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "            ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "            ':c', ':{', '>:\\\\', ';('\n",
    "            ])\n",
    "\n",
    "        #Emoji patterns\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                 u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                 u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                 u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                 u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                 u\"\\U00002702-\\U000027B0\"\n",
    "                 u\"\\U000024C2-\\U0001F251\"\n",
    "                 \"]+\", flags=re.UNICODE)\n",
    "\n",
    "        #combine sad and happy emoticons\n",
    "        emoticons = emoticons_happy.union(emoticons_sad)\n",
    "\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        word_tokens = nltk.word_tokenize(tweet)\n",
    "        #after tweepy preprocessing the colon symbol left remain after      \n",
    "        #removing mentions\n",
    "        tweet = re.sub(r':', '', tweet)\n",
    "        tweet = re.sub(r'â€šÃ„Â¶', '', tweet)\n",
    "\n",
    "        #replace consecutive non-ASCII characters with a space\n",
    "        tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "\n",
    "        #remove emojis from tweet\n",
    "        tweet = emoji_pattern.sub(r'', tweet)\n",
    "\n",
    "        #filter using NLTK library append it to a string\n",
    "        filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "        #looping through conditions\n",
    "        filtered_tweet = []    \n",
    "        for w in word_tokens:\n",
    "        #check tokens against stop words , emoticons and punctuations\n",
    "            if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
    "                filtered_tweet.append(w)\n",
    "\n",
    "        return ' '.join(filtered_tweet)            \n",
    "\n",
    "    def get_tweets(self, keyword, csvfile=\"influencers_new\"):\n",
    "        \n",
    "        \n",
    "        df = pd.DataFrame(columns=self.cols)\n",
    "        \n",
    "        if not csvfile is None:\n",
    "            #If the file exists, then read the existing data from the CSV file.\n",
    "            if os.path.exists(csvfile):\n",
    "                df = pd.read_csv(csvfile, header=0)\n",
    "            \n",
    "\n",
    "        #page attribute in tweepy.cursor and iteration\n",
    "        for page in tweepy.Cursor(self.api.search, q=keyword,count=100, include_rts=False,tweet_mode='extended').pages():\n",
    "\n",
    "            # the you receive from the Twitter API is in a JSON format and has quite an amount of information attached\n",
    "            for status in page:\n",
    "                \n",
    "                new_entry = []\n",
    "                status = status._json\n",
    "                \n",
    "                #filter by language\n",
    "                #if status['lang'] != 'en':\n",
    "                #    continue\n",
    "\n",
    "                \n",
    "                #if this tweet is a retweet update retweet count\n",
    "                if status['created_at'] in df['created_at'].values:\n",
    "                    i = df.loc[df['created_at'] == status['created_at']].index[0]\n",
    "                    #\n",
    "                    cond1 = status['favorite_count'] != df.at[i, 'favorite_count']\n",
    "                    cond2 = status['retweet_count'] != df.at[i, 'retweet_count']\n",
    "                    if cond1 or cond2:\n",
    "                        df.at[i, 'favorite_count'] = status['favorite_count']\n",
    "                        df.at[i, 'retweet_count'] = status['retweet_count']\n",
    "                    continue\n",
    "\n",
    "                #calculate sentiment\n",
    "                filtered_tweet = self.clean_tweets(status['full_text'])\n",
    "                blob = TextBlob(filtered_tweet)\n",
    "                Sentiment = blob.sentiment     \n",
    "                polarity = Sentiment.polarity\n",
    "                subjectivity = Sentiment.subjectivity\n",
    "\n",
    "                new_entry += [status['id'], status['created_at'],\n",
    "                              status['source'], status['full_text'], filtered_tweet, \n",
    "                              Sentiment,polarity,subjectivity, status['lang'],\n",
    "                              status['favorite_count'], status['retweet_count']]\n",
    "\n",
    "                new_entry.append(status['user']['screen_name'])\n",
    "\n",
    "                try:\n",
    "                    is_sensitive = status['possibly_sensitive']\n",
    "                except KeyError:\n",
    "                    is_sensitive = None\n",
    "\n",
    "                new_entry.append(is_sensitive)\n",
    "\n",
    "                hashtags = \", \".join([hashtag_item['text'] for hashtag_item in status['entities']['hashtags']])\n",
    "                new_entry.append(hashtags) #append the hashtags\n",
    "\n",
    "                #\n",
    "                mentions = \", \".join([mention['screen_name'] for mention in status['entities']['user_mentions']])\n",
    "                new_entry.append(mentions) #append the user mentions\n",
    "\n",
    "                try:\n",
    "                    xyz = status['place']['bounding_box']['coordinates']\n",
    "                    coordinates = [coord for loc in xyz for coord in loc]\n",
    "                except TypeError:\n",
    "                    coordinates = None\n",
    "                #\n",
    "                new_entry.append(coordinates)\n",
    "\n",
    "                try:\n",
    "                    location = status['user']['location']\n",
    "                except TypeError:\n",
    "                    location = ''\n",
    "                #\n",
    "                new_entry.append(location)\n",
    "\n",
    "                #now append a row to the dataframe\n",
    "                single_tweet_df = pd.DataFrame([new_entry], columns=self.cols)\n",
    "                df = df.append(single_tweet_df, ignore_index=True)\n",
    "\n",
    "        #\n",
    "        df['timestamp'] = df.created_at.map(pd.Timestamp)\n",
    "        df = df.sort_values('timestamp').set_index('timestamp')\n",
    "        df = df.drop('id',axis=1)\n",
    "        \n",
    "        if not csvfile is None:\n",
    "            #save it to file\n",
    "            df.to_csv(csvfile, columns=self.cols, index=True, encoding=\"utf-8\")\n",
    "            \n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #not sure what I am doing\n",
    "# #how many followers does he have?\n",
    "# influencers_file = 'influencers.csv'\n",
    "# #attempting to get data\n",
    "# if os.path.exists(influencers_file):\n",
    "#     #get file if you have already downloaded what you wanted\n",
    "#     df = pd.read_csv(influencers_file, header=0)\n",
    "#     print (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m51\u001b[0m\n\u001b[1;33m    except AttributeError:  # Not a Retweet\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def scraptweets(search_words, date_since, numTweets, numRuns):\n",
    "    \n",
    "    # Define a for-loop to generate tweets at regular intervals\n",
    "    # We cannot make large API call in one go. Hence, let's try T times\n",
    "    \n",
    "    # Define a pandas dataframe to store the date:\n",
    "    db_tweets = pd.DataFrame(columns = ['username', 'acctdesc', 'location', 'following',\n",
    "                                        'followers', 'totaltweets', 'usercreatedts', 'tweetcreatedts',\n",
    "                                        'retweetcount', 'text', 'hashtags']\n",
    "                                )\n",
    "    program_start = time.time()\n",
    "    for i in range(0, numRuns):\n",
    "        # We will time how long it takes to scrape tweets for each run:\n",
    "        start_run = time.time()\n",
    "        \n",
    "        # Collect tweets using the Cursor object\n",
    "        # .Cursor() returns an object that you can iterate or loop over to access the data collected.\n",
    "        # Each item in the iterator has various attributes that you can access to get information about each tweet\n",
    "        tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\", since=date_since, tweet_mode='extended').items(numTweets)\n",
    "# Store these tweets into a python list\n",
    "        tweet_list = [tweet for tweet in tweets]\n",
    "# Obtain the following info (methods to call them out):\n",
    "        # user.screen_name - twitter handle\n",
    "        # user.description - description of account\n",
    "        # user.location - where is he tweeting from\n",
    "        # user.friends_count - no. of other users that user is following (following)\n",
    "        # user.followers_count - no. of other users who are following this user (followers)\n",
    "        # user.statuses_count - total tweets by user\n",
    "        # user.created_at - when the user account was created\n",
    "        # created_at - when the tweet was created\n",
    "        # retweet_count - no. of retweets\n",
    "        # (deprecated) user.favourites_count - probably total no. of tweets that is favourited by user\n",
    "        # retweeted_status.full_text - full text of the tweet\n",
    "        # tweet.entities['hashtags'] - hashtags in the tweet\n",
    "# Begin scraping the tweets individually:\n",
    "        noTweets = 0\n",
    "for tweet in tweet_list:\n",
    "# Pull the values\n",
    "            username = tweet.user.screen_name\n",
    "            acctdesc = tweet.user.description\n",
    "            location = tweet.user.location\n",
    "            following = tweet.user.friends_count\n",
    "            followers = tweet.user.followers_count\n",
    "            totaltweets = tweet.user.statuses_count\n",
    "            usercreatedts = tweet.user.created_at\n",
    "            tweetcreatedts = tweet.created_at\n",
    "            retweetcount = tweet.retweet_count\n",
    "            hashtags = tweet.entities['hashtags']\n",
    "try:\n",
    "                text = tweet.retweeted_status.full_text\n",
    "            except AttributeError:  # Not a Retweet\n",
    "                text = tweet.full_text\n",
    "# Add the 11 variables to the empty list - ith_tweet:\n",
    "            ith_tweet = [username, acctdesc, location, following, followers, totaltweets,\n",
    "                         usercreatedts, tweetcreatedts, retweetcount, text, hashtags]\n",
    "# Append to dataframe - db_tweets\n",
    "            db_tweets.loc[len(db_tweets)] = ith_tweet\n",
    "# increase counter - noTweets  \n",
    "            noTweets += 1\n",
    "        \n",
    "        # Run ended:\n",
    "        end_run = time.time()\n",
    "        duration_run = round((end_run-start_run)/60, 2)\n",
    "        \n",
    "        print('no. of tweets scraped for run {} is {}'.format(i + 1, noTweets))\n",
    "        print('time take for {} run to complete is {} mins'.format(i+1, duration_run))\n",
    "        \n",
    "        time.sleep(920) #15 minute sleep time\n",
    "# Once all runs have completed, save them to a single csv file:\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Obtain timestamp in a readable format\n",
    "    to_csv_timestamp = datetime.today().strftime('%Y%m%d_%H%M%S')\n",
    "# Define working path and filename\n",
    "    path = os.getcwd()\n",
    "    filename = path + '/data/' + to_csv_timestamp + '_sahkprotests_tweets.csv'\n",
    "# Store dataframe in csv with creation date timestamp\n",
    "    db_tweets.to_csv(filename, index = False)\n",
    "    \n",
    "    program_end = time.time()\n",
    "    print('Scraping has completed!')\n",
    "    print('Total time taken to scrap is {} minutes.'.format(round(program_end - program_start)/60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'ujTOvqIRavCVICVUBi4vw2q53'\n",
    "consumer_secret = 'yjzJxrj1S9aNsmdLhjU0flz8lNgjYDsoG4LXGXwDajxySAe4Rr'\n",
    "access_key= '3403180215-eeVyPBT3lcPW3uB5womtBvYVP2kXRxPImg3dcjk'\n",
    "access_secret = 'olbu14CQniYwzldREuFPLzKxjRXi1VadP0IkzOzlA4AmW'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring file\n",
    "influencers_file = \"influencers.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'created_at', 'source', 'original_text', 'clean_text', 'sentiment', 'polarity', 'subjectivity', 'lang', 'favorite_count', 'retweet_count', 'original_author', 'possibly_sensitive', 'hashtags', 'user_mentions', 'place', 'place_coord_boundaries']\n"
     ]
    }
   ],
   "source": [
    "COLS = ['id', 'created_at', 'source', 'original_text','clean_text', 'sentiment','polarity','subjectivity', 'lang',\n",
    "'favorite_count', 'retweet_count', 'original_author',   'possibly_sensitive', 'hashtags',\n",
    "'user_mentions', 'place', 'place_coord_boundaries']\n",
    "print(COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TweepError",
     "evalue": "[{'code': 215, 'message': 'Bad Authentication data.'}]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-cd8c433b4a06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_user\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gettleman'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# print user.screen_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print user.followers_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    232\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[1;31m# Parse the response payload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTweepError\u001b[0m: [{'code': 215, 'message': 'Bad Authentication data.'}]"
     ]
    }
   ],
   "source": [
    "user = tweepy.api.get_user('gettleman')\n",
    "# print user.screen_name\n",
    "# print user.followers_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
